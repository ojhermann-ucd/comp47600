# imports
import os
import glob
import nltk
from nltk.corpus import stopwords



# GENERAL FUNCTIONS
# directory changes
def go_a_to_tweets():
	os.chdir("Tweets")

def go_tweets_to_a():
	os.chdir("../")

def go_a_to_stop_removed():
	os.chdir("Tweets_no_stop")

def go_stop_removed_to_a():
	os.chdir("../")



# TOKENIZE FUNCTIONS
def tokenize_text_file(file_name):
	"""
	This function generates a token list based on a file input
	"""
	# open the text file that will be tokenized
	with open(file_name, "r") as source:
		# return the tokens generated by reading the source file
		return nltk.word_tokenize(source.read())

def tokenize_text_file_remove_stop_words(file_name):
	"""
	This function generates a token list from an input file and removes stop words
	"""
	# generate the tokens
	tokens = tokenize_text_file(file_name)
	# generate the stop words
	stop_words = set(stopwords.words('english'))
	# return
	return [t for t in tokens if t not in stop_words]



# TF SCORES
def tf_boolean(file_name):
	# data
	token_list = tokenize_text_file_remove_stop_words(file_name)
	frequency_dict = dict()
	# populate frequency_dict
	for token in token_list:
		if token in frequency_dict:
			frequency_dict[token] += 1
		else:
			frequency_dict[token] = 1
	# return frequency_dict
	return frequency_dict



# MATRIX
def get_file_names():
	# file_name_list
	file_name_list = list()
	# iterate over files
	for file_name in glob.glob("*tweet"):
		file_name_list.append(file_name)
	# return file_name_list
	return file_name_list

def get_terms():
	# term_list
	term_dict = dict()
	# iterate over the files
	for file_name in glob.glob("*tweet"):
		# generate a tf_boolean_dict
		tf_boolean_dict = tf_boolean(file_name)
		# iterate over the terms to populate term_dict
		for term in tf_boolean_dict:
			if term in term_dict:
				if file_name in term_dict[term]:
					term_dict[term][file_name] += 1
				else:
					term_dict[term][file_name] = 1
			else:
				term_dict[term] = dict()
				term_dict[term][file_name] = 1
	# return
	return term_dict

def create_matrix():
	# data
	file_name_list = get_file_names()
	file_name_list.insert(0, "")
	term_dict = get_terms()
	# term_list
	term_list = list() # a list of lists
	for term in term_dict:
		temp_list = list()
		for f in file_name_list:
			if f in term_dict[term]:
				temp_list.append(term_dict[term][f])
			else:
				temp_list.append(0)
		term_list.append(temp_list)
	# modify term_list to be the final list
	term_list.insert(0, file_name_list)
	# return 
	return term_list


def print_matrix(matrix):
	for array in matrix:
		print(" ".join(["{:>16}".format(item) for item in array]))